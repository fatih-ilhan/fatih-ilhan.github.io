---
permalink: /
title: "About"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# Fatih Ilhan

## Bio

<div style="text-align: justify"><p>I am a machine learning researcher at Apple. I obtained my CS Ph.D. atÂ Georgia Institute of Technology, advised by <a href="https://www.cc.gatech.edu/~lingliu/">Prof. Ling Liu</a>. I interned as research scientist with Hybrid Cloud Systems Research Group at IBM Research during the summers.</p></div>

<div style="text-align: justify"><p> <b>Research:</b> My current research focus is on-device machine learning optimization techniques and mobile-cloud hybrid computing for scalable application. I have also worked and collaborated on projects related to distillation for LLMs, AI safety, multi-agent AI, distributed learning, reinforcement learning and time series prediction/anomaly detection.</p></div>

<div style="text-align: justify"><p> <b>Teaching:</b> I have served as the head TA of OMS CS6675 (Advanced Internet Systems and Applications) for four semesters and was selected as the Georgia Tech Head TA of the Year in 2025. </p></div>

<div style="text-align: justify"><p> Please refer to my <a href="https://fatih-ilhan.github.io/files/cv.pdf"><b>CV</b></a> for the full record of my work and experience.</p></div>

## Selected Publications

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>FedHFT: Efficient Federated Finetuning with Heterogeneous Edge Clients</b><br>
    <b>F. Ilhan</b>, S. F. Tekin, T. Huang, G. Liu, R. Kompella, G. Eisenhauer, Y. C. Lin, C. Pu and L. Liu.
    <i>IEEE Conference on Cognitive Machine Intelligence </i>, 2025. (<b>IEEE CogMI</b>) [<a href="https://arxiv.org/abs/2510.14054">paper</a>] [<a href="https://github.com/git-disl/FedHFT">code</a>] [<a href="https://gtvault-my.sharepoint.com/:p:/g/personal/filhan3_gatech_edu/EZ1mEF8trdlNrJ__raLQkhoB3_byHED7auLQyK3DoLKDdQ?e=SNn6Me">video</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/fedhft.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>H3 Fusion: Helpful, Harmless, Honest Fusion of Pretrained-LLMs</b><br>
    S. F. Tekin, <b>F. Ilhan</b>, S. Hu, T. Huang, Y. Xu, Z. Yahn, and L. Liu.
    <i>European Chapter of the Association for Computational Linguistics </i>, 2026. (<b>EACL</b>) [<a href="https://openreview.net/pdf?id=RJ5a0hfkmQ">paper</a>] [<a href="https://github.com/git-disl/h3fusion">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/h3fusion.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation</b><br>
    T. Huang, S. Hu, <b>F. Ilhan</b>, S. F. Tekin, and L. Liu.
    <i>International Conference on Learning Representations</i>, 2025. (<b>ICLR oral</b>) [<a href="https://openreview.net/pdf?id=tTPHgb0EtV">paper</a>] [<a href="https://github.com/git-disl/Booster">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/booster.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Adversarial Attention Perturbations for Large Object Detection Transformers</b><br>
    Z. Yahn, S. F. Tekin, <b>F. Ilhan</b>, S. Hu, T. Huang, Y. Xu, M. Loper, and L. Liu.
    <i>International Conference on Computer Vision </i>, 2025. (<b>ICCV</b>) [<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Yahn_Adversarial_Attention_Perturbations_for_Large_Object_Detection_Transformers_ICCV_2025_paper.pdf">paper</a>] [<a href="https://github.com/zacharyyahn/AFOG">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/afog.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Resource-Efficient Transformer Pruning for Finetuning of Large Models</b><br>
    <b>F. Ilhan</b>, G. Su, S. F. Tekin, T. Huang, S. Hu, and L. Liu.
    <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2024. (<b>CVPR</b>) [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Ilhan_Resource-Efficient_Transformer_Pruning_for_Finetuning_of_Large_Models_CVPR_2024_paper.pdf">paper</a>] [<a href="https://github.com/git-disl/recap">code</a>] [<a href="https://youtu.be/wBNWMBugnPY">video</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/recap.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Adaptive Deep Neural Network Inference Optimization with EENet</b><br>
    <b>F. Ilhan</b>, KH. Chow, S. Hu, T. Huang, S. F. Tekin, W. Wei, Y. Wu, M. Lee, R. Kompella, H. Latapie, G. Liu, L. Liu.
    <i>IEEE/CVF Winter Conference on Applications of Computer Vision</i>, 2024. (<b>WACV</b>) [<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Ilhan_Adaptive_Deep_Neural_Network_Inference_Optimization_With_EENet_WACV_2024_paper.pdf">paper</a>] [<a href="https://github.com/git-disl/eenet">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/eenet.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning</b><br>
    T. Huang, S. Hu, <b>F. Ilhan</b>, S. F. Tekin and L. Liu.
    <i>Thirty-seventh Conference on Neural Information Processing Systems</i>, 2024. (<b>NeurIPS</b>) [<a href="https://openreview.net/pdf?id=RPChapuXlC">paper</a>] [<a href="https://github.com/git-disl/Lisa">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/lisa.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity</b><br>
    S. F. Tekin, <b>F. Ilhan</b>, T. Huang, S. Hu and L. Liu.
    <i>ACL Conference on Empirical Methods in Natural Language Processing</i>, 2024. (<b>EMNLP findings</b>) [<a href="https://openreview.net/forum?id=mG5jikbsaJ#discussion">paper</a>] [<a href="https://github.com/git-disl/llm-topla">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/llmtopla.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients</b><br>
    <b>F. Ilhan</b>, G. Su and L. Liu.
    <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2023. (<b>CVPR</b>) [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ilhan_ScaleFL_Resource-Adaptive_Federated_Learning_With_Heterogeneous_Clients_CVPR_2023_paper.pdf">paper</a>] [<a href="https://github.com/git-disl/scale-fl">code</a>] [<a href="https://youtu.be/niOJ1pmVYUM">video</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/scalefl.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Lockdown: Backdoor Defense for Federated Learning with Isolated Subspace Training</b><br>
    T. Huang, S. Hu, <b>F. Ilhan</b>, S. F. Tekin and L. Liu.
    <i>Thirty-seventh Conference on Neural Information Processing Systems</i>, 2023. (<b>NeurIPS</b>) [<a href="https://openreview.net/pdf?id=V5cQH7JbGo">paper</a>] [<a href="https://github.com/git-disl/Lockdown">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/lockdown.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Markovian RNN: An Adaptive Time Series Prediction Network with HMM-based Switching for Nonstationary Environments</b><br>
    <b>F. Ilhan</b>, O. Karaahmetoglu, Ismail Balaban and S. S. Kozat.
    <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2021. (<b>IEEE TNNLS</b>) [<a href="https://ieeexplore.ieee.org/document/9509335">paper</a>] [<a href="https://github.com/fatih-ilhan/markov-rnn">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/markovrnn.png" alt="" style="max-width: 90%; border: 1px solid #eee;">
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 2; padding-right: 20px;">
    <b>Modeling of Spatio-Temporal Hawkes Processes with Randomized Kernels</b><br>
    <b>F. Ilhan</b> and S. S. Kozat.
    <i>IEEE Transactions on Signal Processing</i>, 2020. (<b>IEEE TSP</b>) [<a href="https://ieeexplore.ieee.org/document/9177186">paper</a>] [<a href="https://github.com/fatih-ilhan/sthawkes">code</a>]
  </div>
  <div style="flex: 1;">
    <img src="files/paper_imgs/sthawkes.png" alt="" style="max-width: 70%; border: 1px solid #eee;">
  </div>
</div>
